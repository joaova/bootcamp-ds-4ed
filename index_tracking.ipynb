{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e220f96e-71d4-423a-ab8e-e42a2ddabe3f",
   "metadata": {},
   "source": [
    "# Index Tracking with Gurobi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc494c8a",
   "metadata": {},
   "source": [
    "This Python notebook is part of the webinar [Proven Techniques for Solving Financial Problems with Gurobi](https://www.gurobi.com/events/proven-techniques-for-solving-financial-problems-with-gurobi/).\n",
    "\n",
    "The sequence of python code will:\n",
    "1. Import stock data from yahoo finance\n",
    "2. Clean up the data and change format\n",
    "3. Perform an index tracking experiment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc166daa",
   "metadata": {},
   "source": [
    "## Importing Data from YFinance\n",
    "\n",
    "- Adjusted Stock price data for SP100 constitutents \n",
    "- Data from 2010 to 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02ad0025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "from curl_cffi import requests\n",
    "from io import StringIO\n",
    "\n",
    "session = requests.Session(impersonate=\"chrome\")\n",
    "ticker = yf.Ticker('...', session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7ecf5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options\n",
    "FIRST_DATE  = \"2020-01-01\"\n",
    "LAST_DATE   = \"2025-01-01\"\n",
    "N_PROCESSES = 10\n",
    "MKT_INDEX   = \"^SP100\" # ^GSPC for SP500 or ^SP100 \n",
    "#MKT_INDEX   = \"^GSPC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93f55ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[************          26%                       ]  27 of 102 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  102 of 102 completed\n",
      "\n",
      "102 Failed downloads:\n",
      "['TGT', 'COF', 'GOOGL', 'MET', 'FDX', 'BLK', 'COST', 'NEE', 'TMUS', 'PFE', 'T', 'MDT', 'LLY', 'NFLX', 'BRK-B', 'META', 'PYPL', 'COP', 'GD', 'SCHW', 'QCOM', 'BKNG', 'HD', 'JPM', 'RTX', 'AMZN', 'INTC', 'JNJ', 'ADBE', 'KO', 'SBUX', 'CMCSA', 'AAPL', 'AXP', 'NKE', 'AMT', 'DHR', 'BMY', 'AIG', 'NOW', 'MMM', 'MDLZ', 'WMT', 'TSLA', 'MRK', 'CSCO', 'WFC', 'BK', 'LOW', 'USB', 'DE', 'UPS', 'XOM', 'CRM', 'PM', 'INTU', 'MS', 'SPG', 'TMO', 'GOOG', 'TXN', 'ORCL', 'DUK', 'HON', 'LIN', 'AMGN', 'UNH', 'MCD', 'ABBV', 'ACN', 'AVGO', 'MSFT', 'AMD', 'NVDA', 'BAC', '^SP100', 'ABT', 'DIS', 'VZ', 'GM', 'BA', 'EMR', 'ISRG', 'LMT', 'MA', 'PEP', 'MO', 'CVS', 'CVX', 'UBER', 'CAT', 'PLTR', 'UNP', 'IBM', 'PG', 'V', 'SO', 'C', 'GE', 'GILD', 'GS', 'CL']: AttributeError(\"'str' object has no attribute 'name'\")\n"
     ]
    }
   ],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/S%26P_100'\n",
    "\n",
    "header = {\n",
    "  \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36\",\n",
    "  \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "}\n",
    "\n",
    "r = requests.get(url, headers=header)\n",
    "\n",
    "sp_assets = pd.read_html(StringIO(r.text))[2]\n",
    "\n",
    "assets = sp_assets['Symbol'].str.replace('.', '-').tolist()\n",
    "\n",
    "assets.append('^SP100')\n",
    "\n",
    "data = yf.download(assets, start=FIRST_DATE, end=LAST_DATE)[\"Close\"]\n",
    "\n",
    "data = data.reset_index()\n",
    "\n",
    "df = data.melt(id_vars=['Date'], var_name='Ticker', value_name='Price')\n",
    "\n",
    "df.to_csv(\"df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94591a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4ca1f74",
   "metadata": {},
   "source": [
    "## Cleaning and Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029a358e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "THRESH_VALID_DATA = 0.95 # defines where to cut stocks with missing data\n",
    "PERC_SIZE_TRAIN = 0.75   # defines the size of train dataset (in %)\n",
    "\n",
    "df_ret, df_train, df_test  = clean_data(\n",
    "    df_prices, \n",
    "    MKT_INDEX,\n",
    "    thresh_valid_data = THRESH_VALID_DATA,\n",
    "    size_train = PERC_SIZE_TRAIN\n",
    ")\n",
    "\n",
    "df_train.to_parquet(\"data/ret-data-cleaned-TRAIN.parquet\")\n",
    "df_test.to_parquet(\"data/ret-data-cleaned-TEST.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8713c0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide = df.pivot(index = 'Date', columns = 'Ticker', values = 'Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deae3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uma forma de padronizar os dados, nao sei se eh necessario\n",
    "#std_df_wide = (df_wide-df_wide.mean())/df_wide.std()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b9ff5bc-99e7-40ca-b7d8-fa567f100c7f",
   "metadata": {},
   "source": [
    "## Unconstrained Index Tracking\n",
    "\n",
    "$\n",
    "\\begin{array}{llll}\n",
    "  & \\min              & \\frac{1}{T} \\; \\sum_{t = 1}^{T} \\left(\\sum_{i = 1}^{I} \\; w_{i} \\: \\times \\: r_{i,t} - R_{t}\\right)^2 \\\\\n",
    "  & \\text{subject to} &   \\sum_{i = 1}^{I} w_{i}  = 1  \\\\\n",
    "  &                   & w_i \\geq 0 \\\\\n",
    "\\end{array}\n",
    "$\n",
    "\n",
    "\n",
    "\n",
    "$\n",
    "\\begin{array}{lll}\n",
    "& where: \\\\\n",
    "& \\\\\n",
    "& w_i  &: \\text{Weight of asset i in index} \\\\\n",
    "& R_{t} &: \\text{Returns of tracked index (e.g. SP500) at time t} \\\\\n",
    "& r_{i,j} &: \\text{Return of asset i at time t}\n",
    "\\end{array}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d35d832",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'^SP100'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joaov\\Documents\\bootcamp-ds-4ed\\envs\\default\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: '^SP100'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     10\u001b[39m r_it = df_wide\n\u001b[32m     12\u001b[39m r_it.dropna(inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m r_mkt = \u001b[43mr_it\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmkt_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     16\u001b[39m r_it = r_it.drop(mkt_index, axis = \u001b[32m1\u001b[39m)\n\u001b[32m     18\u001b[39m tickers = \u001b[38;5;28mlist\u001b[39m(r_it.columns)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joaov\\Documents\\bootcamp-ds-4ed\\envs\\default\\Lib\\site-packages\\pandas\\core\\frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joaov\\Documents\\bootcamp-ds-4ed\\envs\\default\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: '^SP100'"
     ]
    }
   ],
   "source": [
    "import gurobipy as gp\n",
    "from random import sample, seed\n",
    "\n",
    "seed(20220209) # reproducibility\n",
    "\n",
    "mkt_index = \"^SP100\"\n",
    "n_assets = 20\n",
    "\n",
    "# data from main notebook\n",
    "r_it = df_wide\n",
    "\n",
    "r_it.dropna(inplace=True)\n",
    "\n",
    "r_mkt = r_it[mkt_index]\n",
    "\n",
    "r_it = r_it.drop(mkt_index, axis = 1)\n",
    "\n",
    "tickers = list(r_it.columns)\n",
    "\n",
    "sampled_tickers = sample(tickers, n_assets)\n",
    "\n",
    "r_it = r_it[sampled_tickers]\n",
    "\n",
    "print(r_it.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a033a00-9402-4833-8782-aa31a36f76ad",
   "metadata": {},
   "source": [
    "# Setup opt problem and solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cac2d632-8e73-4ccd-82f6-064c0f932e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restricted license - for non-production use only - expires 2026-11-23\n",
      "Solution:\n",
      "RTX:\t 0.00%\n",
      "ABT:\t 0.00%\n",
      "AMD:\t 0.00%\n",
      "MS:\t 0.00%\n",
      "MA:\t 0.00%\n",
      "INTU:\t 0.00%\n",
      "SBUX:\t 0.00%\n",
      "HD:\t 0.00%\n",
      "LLY:\t 0.00%\n",
      "MDLZ:\t 0.00%\n",
      "PFE:\t 0.00%\n",
      "SPG:\t 0.00%\n",
      "UNH:\t 0.00%\n",
      "GD:\t 0.00%\n",
      "MO:\t 0.00%\n",
      "AVGO:\t 0.00%\n",
      "BLK:\t 100.00%\n",
      "IBM:\t 0.00%\n",
      "GOOG:\t 0.00%\n",
      "BAC:\t 0.00%\n",
      "\n",
      "checking constraints:\n",
      "sum(w) = 1.0000000000001181\n"
     ]
    }
   ],
   "source": [
    "# Create an empty model\n",
    "m = gp.Model('gurobi_index_tracking')\n",
    "\n",
    "# PARAMETERS \n",
    "\n",
    "# w_i: the i_th stock gets a weight w_i\n",
    "w = pd.Series(m.addVars(sampled_tickers, \n",
    "                         lb = 0,\n",
    "                         ub = 1,\n",
    "                         vtype = gp.GRB.CONTINUOUS), \n",
    "               index=sampled_tickers)\n",
    "\n",
    "# CONSTRAINTS\n",
    "\n",
    "# sum(w_i) = 1: portfolio budget constrain (long only)\n",
    "m.addConstr(w.sum() == 1, 'port_budget')\n",
    "\n",
    "m.update()\n",
    "\n",
    "# eps_t = R_{i,t}*w - R_{M,t}\n",
    "my_error = r_it.dot(w) - r_mkt\n",
    "\n",
    "# set objective function\n",
    "m.setObjective(\n",
    "    gp.quicksum(my_error.pow(2)), \n",
    "    gp.GRB.MINIMIZE)     \n",
    "\n",
    "# Optimize model\n",
    "m.setParam('OutputFlag', 0)\n",
    "m.optimize()\n",
    "\n",
    "w_hat  = [i.X for i in m.getVars()]\n",
    "\n",
    "print(f\"Solution:\") \n",
    "\n",
    "for i, i_ticker in enumerate(sampled_tickers):\n",
    "    print(f\"{i_ticker}:\\t {w_hat[i]*100:.2f}%\")\n",
    "\n",
    "# check constraints\n",
    "print(f\"\\nchecking constraints:\")\n",
    "print(f\"sum(w) = {np.sum(w_hat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4045ebc9-b04d-4b54-a888-041c4e4b8092",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_wide' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# alterar\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m df_test = \u001b[43mdf_wide\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(df_test.columns)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(sampled_tickers)\n",
      "\u001b[31mNameError\u001b[39m: name 'df_wide' is not defined"
     ]
    }
   ],
   "source": [
    "# check out of sample plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# aqui coloquei qualquer coisa so pra testar\n",
    "df_test = df_wide\n",
    "\n",
    "print(df_test.columns)\n",
    "print(sampled_tickers)\n",
    "df_test_mkt = df_test[mkt_index]\n",
    "\n",
    "r_hat = df_test[sampled_tickers].dot(w_hat)\n",
    "\n",
    "cumret_r = np.cumprod(1+ r_hat)\n",
    "cumret_mkt = np.cumprod(1+ df_test_mkt)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(cumret_mkt.index,\n",
    "        cumret_mkt, \n",
    "       label = mkt_index)\n",
    "\n",
    "ax.plot(cumret_r.index,\n",
    "        cumret_r,\n",
    "       label = f\"ETF ({n_assets} assets)\")\n",
    "\n",
    "ax.legend()\n",
    "ax.set_title(f'ETF and {mkt_index}')\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Cumulative Returns')\n",
    "\n",
    "plt.xticks(rotation = 90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3239ca8-ea6d-40e5-854f-a21bd517c7c1",
   "metadata": {},
   "source": [
    "## Constrained Index Tracking\n",
    "\n",
    "$\n",
    "\\begin{array}{llll}\n",
    "  & \\min              & \\frac{1}{T} \\; \\sum_{t = 1}^{T} \\left(\\sum_{i = 1}^{I} \\; w_{i} \\: \\times \\: r_{i,t} - R_{t}\\right)^2 \\\\\n",
    "  & \\text{subject to} &   \\sum_{i = 1}^{I} w_{i}  = 1  \\\\\n",
    "  &                   &   \\sum_{i = 1}^{I} z_{i} \\leq K \\\\\n",
    "  &                   & w_i \\geq 0 \\\\\n",
    "  &                   & z_i \\in {0, 1}\n",
    "\\end{array}\n",
    "$\n",
    "\n",
    "  \n",
    "\n",
    "$\n",
    "\\begin{array}{lllll}\n",
    "& where: \\\\\n",
    "& \\\\\n",
    "& w_i  &: \\text{Weight of asset i in index} \\\\\n",
    "& z_i &: \\text{Binary variable (0, 1) that decides wheter asset i is in portfolio} \\\\\n",
    "& R_{t} &: \\text{Returns of tracked index (e.g. SP500) at time t} \\\\\n",
    "& r_{i,j} &: \\text{Return of asset i at time t}\n",
    "\\end{array}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40631468-36d9-41aa-a684-6f103a95340b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution for w:\n",
      "QCOM:\t 2.82%\n",
      "ABT:\t 0.00%\n",
      "AMD:\t 8.52%\n",
      "MRK:\t 0.00%\n",
      "LOW:\t 0.00%\n",
      "INTU:\t 8.67%\n",
      "RTX:\t 0.00%\n",
      "HD:\t 0.00%\n",
      "LIN:\t 0.00%\n",
      "MCD:\t 0.00%\n",
      "PEP:\t 0.00%\n",
      "SO:\t 6.76%\n",
      "TXN:\t 0.69%\n",
      "GD:\t 0.00%\n",
      "MMM:\t 0.00%\n",
      "AVGO:\t 20.00%\n",
      "BLK:\t 18.60%\n",
      "XOM:\t 0.00%\n",
      "IBM:\t 13.94%\n",
      "GOOG:\t 20.00%\n",
      "\n",
      "checking constraints:\n",
      "sum(w) = 1.0\n",
      "sum(z) = 9.0\n",
      "w <= z = True\n",
      "MIPGap=0.0\n",
      "Status=2\n"
     ]
    }
   ],
   "source": [
    "# Create an empty model\n",
    "m = gp.Model('gurobi_index_tracking')\n",
    "\n",
    "# PARAMETERS \n",
    "\n",
    "max_assets = 10\n",
    "\n",
    "# w_i: the i_th stock gets a weight w_i\n",
    "w = pd.Series(m.addVars(sampled_tickers, \n",
    "                         lb = 0,\n",
    "                         ub = 0.2,\n",
    "                         vtype = gp.GRB.CONTINUOUS), \n",
    "               index=sampled_tickers)\n",
    "\n",
    "# [NEW] z_i: the i_th stock gets a binary z_i\n",
    "z = pd.Series(m.addVars(sampled_tickers,\n",
    "                        vtype = gp.GRB.BINARY),\n",
    "                index=sampled_tickers)\n",
    "\n",
    "# CONSTRAINTS\n",
    "\n",
    "# sum(w_i) = 1: portfolio budget constrain (long only)\n",
    "m.addConstr(w.sum() == 1, 'port_budget')\n",
    "\n",
    "# [NEW]  w_i <= z_i: restrictions of values of w_i so take it chose particular tickers\n",
    "for i_ticker in sampled_tickers:\n",
    "    m.addConstr(w[i_ticker] <= z[i_ticker], \n",
    "                f'dummy_restriction_{i_ticker}')\n",
    "\n",
    "# [NEW] sum(z_i) <= max_assets: number of assets constraint\n",
    "m.addConstr(z.sum() <= max_assets, 'max_assets_restriction')\n",
    "\n",
    "m.update()\n",
    "\n",
    "# eps_t = R_{i,t}*w - R_{M,t}\n",
    "my_error = r_it.dot(w) - r_mkt\n",
    "\n",
    "# set objective function\n",
    "m.setObjective(\n",
    "    gp.quicksum(my_error.pow(2)), \n",
    "    gp.GRB.MINIMIZE)     \n",
    "\n",
    "# Optimize model\n",
    "m.setParam('OutputFlag', 0)\n",
    "m.setParam('TimeLimit', 60*5) # in secs\n",
    "#m.setParam('MIPGap', 0.05) # in secs\n",
    "m.optimize()\n",
    "\n",
    "params = [i.X for i in m.getVars()]\n",
    "\n",
    "n_assets = len(sampled_tickers)\n",
    "w_hat = params[0:n_assets]\n",
    "z_hat = params[n_assets:]\n",
    "MIPGap = m.getAttr('MIPGap')\n",
    "status = m.getAttr(\"Status\")\n",
    "\n",
    "print(f\"Solution for w:\") \n",
    "\n",
    "for i, i_ticker in enumerate(sampled_tickers):\n",
    "    print(f\"{i_ticker}:\\t {w_hat[i]*100:.2f}%\")\n",
    "\n",
    "# check constraints\n",
    "print(f\"\\nchecking constraints:\")\n",
    "print(f\"sum(w) = {np.sum(w_hat)}\")\n",
    "print(f\"sum(z) = {np.sum(z_hat)}\")\n",
    "print(f\"w <= z = {w_hat <= z_hat}\")\n",
    "print(f\"MIPGap={MIPGap}\")\n",
    "print(f\"Status={status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97b2516a-14c9-436b-a6b9-9dfb973ea0b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# check out of sample plot\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m df_test = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/ret-data-cleaned-TEST.parquet\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(df_test.columns)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(sampled_tickers)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joaov\\Documents\\bootcamp-ds-4ed\\envs\\default\\Lib\\site-packages\\pandas\\io\\parquet.py:653\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[39m\n\u001b[32m    500\u001b[39m \u001b[38;5;129m@doc\u001b[39m(storage_options=_shared_docs[\u001b[33m\"\u001b[39m\u001b[33mstorage_options\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_parquet\u001b[39m(\n\u001b[32m    502\u001b[39m     path: FilePath | ReadBuffer[\u001b[38;5;28mbytes\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    510\u001b[39m     **kwargs,\n\u001b[32m    511\u001b[39m ) -> DataFrame:\n\u001b[32m    512\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    513\u001b[39m \u001b[33;03m    Load a parquet object from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[32m    514\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    650\u001b[39m \u001b[33;03m    1    4    9\u001b[39;00m\n\u001b[32m    651\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m653\u001b[39m     impl = \u001b[43mget_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m use_nullable_dtypes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib.no_default:\n\u001b[32m    656\u001b[39m         msg = (\n\u001b[32m    657\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe argument \u001b[39m\u001b[33m'\u001b[39m\u001b[33muse_nullable_dtypes\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is deprecated and will be removed \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    658\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33min a future version.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    659\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joaov\\Documents\\bootcamp-ds-4ed\\envs\\default\\Lib\\site-packages\\pandas\\io\\parquet.py:68\u001b[39m, in \u001b[36mget_engine\u001b[39m\u001b[34m(engine)\u001b[39m\n\u001b[32m     65\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m     66\u001b[39m             error_msgs += \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m - \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(err)\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     69\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUnable to find a usable engine; \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     70\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtried using: \u001b[39m\u001b[33m'\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mfastparquet\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     71\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mA suitable version of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     72\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpyarrow or fastparquet is required for parquet \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     73\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msupport.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     74\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTrying to import the above resulted in these errors:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     75\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_msgs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     76\u001b[39m     )\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m engine == \u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m PyArrowImpl()\n",
      "\u001b[31mImportError\u001b[39m: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet."
     ]
    }
   ],
   "source": [
    "# check out of sample plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_test = pd.read_parquet(\"data/ret-data-cleaned-TEST.parquet\")\n",
    "\n",
    "print(df_test.columns)\n",
    "print(sampled_tickers)\n",
    "df_test_mkt = df_test[mkt_index]\n",
    "\n",
    "r_hat = df_test[sampled_tickers].dot(w_hat)\n",
    "\n",
    "cumret_r = np.cumprod(1+ r_hat)\n",
    "cumret_mkt = np.cumprod(1+ df_test_mkt)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(cumret_mkt.index,\n",
    "        cumret_mkt, \n",
    "       label = mkt_index)\n",
    "\n",
    "ax.plot(cumret_r.index,\n",
    "        cumret_r,\n",
    "       label = f\"ETF ({n_assets} assets)\")\n",
    "\n",
    "ax.legend()\n",
    "ax.set_title(f'ETF and {mkt_index}')\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Cumulative Returns')\n",
    "\n",
    "plt.xticks(rotation = 90)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
